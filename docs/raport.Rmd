---
title: "Równoważenie obciążenia przez alokację shardów bazującą na predykcji obciążenia"
author: 
  - Damian Szkudlarek
  - Wojciech Taisner
  - Michał Włodarczyk
# date: "`r format(Sys.time(), '%d.%m.%Y r.')`"
output:
  html_document: 
    theme: spacelab
    df_print: paged
    
---
<style>
body {
text-align: justify;
color: black}
</style>

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(DT)
```

# Algorytmy przydziału
### BestFit (BF)
Algorytm redukuje problem alokacji shardów do problemu szeregowania P || Cmax.

Węzły są traktowane jako równoległe maszyny, shardy jako niepodzielne zadania, wektor obciążenia shardu jest redukowany do średniej jego elementów, ta średnia jest długością trwania zadania.


Metoda BestFit w każdej iteracji dodaje shard do węzła, w taki sposób, aby pozostawić jak najmniej wolnego miejsca,
dopóki wolne miejsce jest i shard się mieści  na węzeł. Po zapełnieniu węzła, algorytm przechodzi do kolejnego. 
Ewentualne, nie przydzielone shardy są przydzielane kolejno na węzły o najmniejszym obciążeniu.


### RoundRobin (RR)
Podejście naiwne - przydział zadań na węzły po kolei, algorytmem Round Robin, bez uprzedniego szeregowania węzłów.

### SALP
Algorytm pierwotnej alokacji shardów – SALP (Shards Allocation based on Load Prediction) - zgodnie ze specyfikacją.

# Eksperyment

## Parametry eksperymentu

Lista wybranych parametrów dla symulacji:

1. Liczba węzłów $N=100$
2. Liczba shardów $F=1000$ (średnio 10 shardów na węzeł)
3. Długość cyklu - ilość elementów w cyklu (size) $S=100$

Sposób generowania danych przez generator rozkładu gamma: 

1. Losowanie parametrów skali $\theta$ dla shardów z rozkładu gamma o kształcie $k=2$ i skali $\theta=5$
2. Generowanie $S$ wartości dla każdego z $F$ shardów z rozkładu gamma o kształcie $k=2$ i skali $\theta$ wylosowanej jak opisano w punkcie 1.

Parametry generowania danych w "Nowym modelu obciążenia":

1. Generacja wartości dolnej $low$ z rozkładu jednostajnego (1,5), generacja wartości $gap$ (wartość górna $high = low + gap$) z rozkładu jednostajnego (1,5)
2. Generacja wartości kąta przechyłu z zakresu <-15; 15> (stopni)
3. Co drugi wektor obciążenia "odwrócony"


## Opis Eksperymentu

W przypadku danych wygenerowanych z rozkładu gamma, dla każdej wartośći współczynnika korelacji z zakresu <0;1> z krokiem 0.05 wygenerowano po 100 różnych zestawów danych, razem 2100 zestawów. Dla każdej generacji, wartość ziarna generatorów liczb losowych była ustalona jako numer powtórzenia, czyli kolejne liczby z zakresu <0;99> (w celu zapewnienia powtarzalności).

W przypadku danych generowanych według "Nowego modelu obciążenia", ze względu na brak dodatkowej parametryzacji, wygenerowano jedynie 100 razy ten sam zestaw danych, za każdym razem zmieniając ziarno generatora liczb losowych, analogicznie do sposobu opisanego powyżej.

Po uzyskaniu wszystkich zestawów danych, uruchamiano na nich algorytmy w celu uzyskania przydziału shardów do węzłów, a następnie wyliczano wektory obciążenia węzłów. W przypadku danych generowanych z rozkładu gamma, uzyskano łącznie 6300 zestawów obciążeń węzłów, a w drugim wypadku analogicznie 300 zestawów.

Kolejnym krokiem była ewaluacja obciążeń węzłów, dla każdego zestawu i każdej z zadanych wartości współczynnika obciążenia (zakres <0.5; 0.9> krok 0.05), wyliczane były miary według zadanych wzorów.

Niezmienność danych była uzyskiwana poprzez kopiowanie rezultatów uzyskanych przez algorytmy, w przypadku gdy do wektorów obciążeń węzłów były wprowadzanae zmiany, np. gdy była wymagana alokacja nadmiarowego obciążenia.

Kopiowanie uzyskanych rezultatów okazało się bardziej efektywne niż generacja i powtórne szeregowanie takiego samego zestawu danych, co pozwoliło znacząco skrócić czas trwania symulacji.

Powyższy opis można przedstawić przy użyciu poniższego pseudokodu (dla przypadku generacji danych ze współczynnikiem korelacji)

```
# double loop, correlation and repeats 
FOR correlaction_coefficient IN <0;1> step 0.05; FOR r IN <0;99>;
BEGIN:
  shards = GENERATE_SHARDS(correlaction_coefficient, seed=r)
  FOR EACH algorithm OF algorithm_list:
  BEGIN:
    nodes = algorithm.shard_assignment(shards)
    FOR load IN <0.5; 0.9> step 0.05
    BEGIN:
      result = evaluate(nodes, load) # copy nodes
      # save  single record of results
      YIELD result 
    END
  END
END
```

# Wyniki eksperymentu

Niniejsza sekcja zawiera wykresy prezentujące dane, uzyskane podczas przeprowadzonych symulacji. 

## Dane generowane z rozkładu Gamma

```{r}
df <- read.csv(file = '../results/N100-F1000-S100-R100-result-v14.csv') %>% mutate(algorithm = factor(algorithm)) %>% select(-v1) %>% rename(value=v2)
df_rounded <- df %>% mutate(across(where(is.numeric), ~ round(., 2)))
```


### Czas opóźnień, a korelacja

Poniższy wykres jest zbiorczy dla wszystkich obciążeń. Osie są stałe, aby umożliwić porównanie zmiany w czasie oczekiwania przy różnych stopniach obciążenia węzłów i współczynnikach korelacji.

```{r fig.width=10, fig.height=10}
waitT <- df_rounded %>% 
  group_by(algorithm, correlation, load) %>% 
  mutate(mean_waiting_time = median(value, na.rm = TRUE)) %>% 
  rename(`obciążenie`=`load`) %>% ungroup() %>% 
  select(-(4:7)) %>%  distinct()

waitT %>% filter(`obciążenie` <= 0.7) %>%
ggplot(aes(x=correlation, y=mean_waiting_time, colour=algorithm)) +
  geom_line(size=1)+
  facet_wrap(`obciążenie`~.,  labeller = label_both, ncol=2)+
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="współczynnik korelacji", 
       y="średni czas opóźnienia", 
       colour="algorytm", 
       title = "Średni czas opóźnień na węzłach w zależności od współczynnika korelacji")
```

Dla wartości obciążenia większych niż `0.7` przedstawiono zależności na osobnych wykresach.

```{r fig.width=10, fig.height=5}
waitT %>% filter(`obciążenie` > 0.7) %>% filter(correlation < 0.3) %>%
ggplot(aes(x=correlation, y=mean_waiting_time, colour=algorithm)) +
  geom_line(size=1)+
  facet_wrap(`obciążenie`~.,  labeller = label_both, ncol=2)+
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="współczynnik korelacji", 
       y="średni czas opóźnienia", 
       colour="algorytm", 
       title = "Średni czas opóźnień na węzłach w zależności od współczynnika korelacji")
```


### Czas opóźnień, a obciążenie

Poniższe wykresy są uzupełnieniem do poprzedniej sekcji, pokazują zmianę czasu opóźnienia, w stosunku do obciążenia dla wybranych wartości korelacji.

```{r fig.width=10, fig.height=10}
corrs <- c(0,.25,.5,.75,1)

waitT %>% filter(correlation %in% corrs)%>% rename(`współczynnik korelacji`=correlation) %>%
  ggplot(aes(x=`obciążenie`, y=mean_waiting_time, colour=algorithm)) +
  # geom_smooth(size=1)+
  geom_line(size=1)+
  # geom_point(size=3)+
  facet_wrap(`współczynnik korelacji`~.,  labeller = label_both, ncol=2)+
  theme(text=element_text(size=14),
        panel.grid.major  = element_line(colour="grey60"),
        panel.spacing.y = unit(1, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="obciążenie", 
       y="średni czas opóźnienia", colour="algorytm", 
       title = "Średni czas opóźnień na węzłach w zależności od ich obciążenia")
```

### Ilość wyników w zależności od obciażenia

Poniższa tabela prezentuje ilość poprawnych (takich gdzie każdy węzeł jest stabilny) przyporządkowań shardów do węzłów wygenerowanych przed dany algorytm w zależności od obciążenia

```{r}
knitr::kable(
df %>% 
  filter(!is.na(value)) %>% 
  group_by(algorithm, load) %>% count()
)
```

Należy zwrócić uwagę na to, że algorytm $RR$ nie był w stanie wygenerować poprawnego przyporządkowania dla wartości obciążenia $\rho > 0.7$, a dla wartości $\rho > 0.55$ wygenerowanych przyporządkowań jest na tyle mało, że nie ma pewności co do tego czy te wartości są repreznetatywne.

### Niezrównoważenie obciążenia, a korelacja

Kolejny wykres prezentuje niezrównoważenie w zależności od współczynnika korelacji.

```{r fig.width=10, fig.height=5}
disturb <- df %>% group_by(algorithm, correlation) %>% mutate(disturbance = mean(disturbance, na.rm = TRUE)) %>% ungroup() %>% select(correlation, algorithm, disturbance)  %>%  distinct() 

disturb %>%
ggplot(aes(x=correlation, y=disturbance, colour=algorithm)) +
  geom_line(size=1)+
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="współczynnik korelacji", 
       y="względne niezrównoważenie obciążenia", colour="algorytm", 
       title = "Względne niezrównoważenie obciążenia chmury w zależności od współczynnika korelacji")
```
<br/>
<br/>

### Obciążenie chmury, a korelacja

Poniższy wykres dotyczy generowanych danych, linia ciągła prezentuje średnie sumaryczne obciążenie chmury, a prosta linia przerywana to wartość estymowana na podstawie parametrów generacji.


```{r fig.width=10, fig.height=5}
actLoads <- df %>% group_by(correlation) %>% mutate(actual_load = mean(actual_load, na.rm = TRUE)) %>% ungroup() %>% select(correlation, actual_load) %>%  distinct()

est <- 2.0 * 10**6

actLoads %>%
ggplot(aes(x=correlation, y=actual_load, colour="rzeczywiste")) +
  geom_line(size=1.2)+
  geom_hline(aes(yintercept=est, colour="estymowane"), size=1.1, linetype="dashed")+
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="współczynnik korelacji", 
       y="obciążenie chmury", 
       colour="", 
       title = "Obciążenie chmury w zależności od współczynnika korelacji")
```

### Współczynnik zmienności częstości przedkładania zadań, a korelacja

Poniższy wykres wskazuje na powiązanie wartości zmienności częstości przedkładania zadań, z wartością współczynnika korelacji.

```{r fig.width=12, fig.height=5}
df_rounded %>% group_by(algorithm, correlation) %>% 
  mutate(mean_ca = mean(mean_ca, na.rm = TRUE)) %>% ungroup() %>% 
  select(algorithm, correlation, mean_ca) %>%  distinct() %>%
ggplot(aes(x=correlation, y=mean_ca, colour=algorithm)) +
  geom_line(size=1)+
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="współczynnik korelacji", 
       y="zmiennośc częstości przedkładania zadań", 
       colour="algorytm", 
       title = "Współczynnik zmienności częstości przedkładania zadań w zależności od współczynnika korelacji")
```

```{r fig.width=12, fig.height=5}
df_rounded %>% group_by(algorithm, load) %>% 
  mutate(mean_ca = mean(mean_ca, na.rm = TRUE)) %>% ungroup() %>% 
  select(algorithm, load, mean_ca) %>%  distinct() %>%
ggplot(aes(x=load, y=mean_ca, colour=algorithm)) +
  geom_line(size=1)+
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="wartość obciążenia", 
       y="zmiennośc częstości przedkładania zadań", 
       colour="algorytm", 
       title = "Współczynnik zmienności częstości przedkładania zadań w zależności od wartości obciążenia")
```

## Dane generowane według "Nowego modelu obciążenia"

W tej sekcji przedstawione są wyniki dodatkowego eksperymentu, w którym dane były generowane według "nowego modelu obciążeń" (opisanego w jednej z wersji opisu problemu). W związku z tym, że dla tak generowanych danych, proces nie uwzględniał zmiany współczynnika korelacji, wystarczy przedstawic jedynie zależność czasu opóźnienia od obciążenia.

```{r}
df <- read.csv(file = '../results/N100-F1000-S100-R100-result-v15.csv') %>% 
  mutate(algorithm = factor(algorithm)) %>% 
  select(-v1) %>% select(-correlation) %>%
  rename(value=v2)
df_rounded <- df %>% mutate(across(where(is.numeric), ~ round(., 2)))
```

```{r fig.width=10}
df %>% group_by(algorithm, load) %>% 
  mutate(mean_waiting_time = median(value, na.rm = TRUE)) %>% 
  ggplot(aes(x=load, y=mean_waiting_time, colour=algorithm)) + geom_line(size=1) +
  theme(text=element_text(size=14),
        axis.text=element_text(size=8),
        panel.grid.major  = element_line(colour="grey60"),
        # panel.spacing.y = unit(0.5, "lines"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "right")+
  labs(x="obciążenie", 
       y="mediana czasu opóżnień", colour="algorytm", 
       title = "Czas opóżnień w zależności od obciążenia")
```
